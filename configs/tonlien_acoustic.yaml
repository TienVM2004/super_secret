base_config:
  - configs/base.yaml

pl_trainer_precision: '16-mixed'
pe: 'rmvpe'
pe_ckpt: 'checkpoints/rmvpe/model.pt'

task_cls: training.acoustic_task.AcousticTask
spk_ids: []

num_spk: 1
speakers:
  - tonlien #0

test_prefixes: 
  # tonlien (0)
  - 0:tiger_001_seg005
  - 0:tiger_006_seg003
  - 0:tiger_010_seg003
  - 0:tiger_013_seg009

vocoder: NsfHifiGAN
vocoder_ckpt: checkpoints/nsf_hifigan/model
audio_sample_rate: 44100
audio_num_mel_bins: 128
hop_size: 512            # Hop size.
fft_size: 2048           # FFT size.
win_size: 2048           # FFT size.
fmin: 40
fmax: 16000

binarization_args:
  shuffle: true
  num_workers: 0
augmentation_args:
  random_pitch_shifting:
    enabled: false
    range: [-5., 5.]
    scale: 0.75
  fixed_pitch_shifting:
    enabled: false
    targets: [-5., 5.]
    scale: 0.5
  random_time_stretching:
    enabled: false
    range: [0.5, 2.]
    domain: log  # or linear
    scale: 0.75

raw_data_dir: 'data\training_data\tonlien'
binary_data_dir: 'data/binary/tonlien_v1'
binarizer_cls: preprocessing.acoustic_binarizer.AcousticBinarizer
dictionary: dictionaries\tonlien_dictionary.txt
num_pad_tokens: 1
spec_min: [-5]
spec_max: [0]
mel_vmin: -6. #-6.
mel_vmax: 1.5
interp_uv: true
energy_smooth_width: 0.12
breathiness_smooth_width: 0.12

use_spk_id: false
f0_embed_type: discrete
use_energy_embed: false
use_breathiness_embed: false
use_key_shift_embed: false
use_speed_embed: false

timesteps: 1000
max_beta: 0.02
rel_pos: true
diff_accelerator: ddim
pndm_speedup: 10
hidden_size: 256
residual_layers: 20
residual_channels: 512
dilation_cycle_length: 4  # *
diff_decoder_type: 'wavenet'
diff_loss_type: l2
schedule_type: 'linear'

# shallow diffusion
use_shallow_diffusion: true
K_step: 400
K_step_infer: 400

shallow_diffusion_args:
  train_aux_decoder: true
  train_diffusion: true
  val_gt_start: false
  aux_decoder_arch: convnext
  aux_decoder_args:
    num_channels: 512
    num_layers: 6
    kernel_size: 7
    dropout_rate: 0.1
  aux_decoder_grad: 0.1

lambda_aux_mel_loss: 0.2

# train and eval
num_sanity_val_steps: 1
optimizer_args:
  lr: 0.0006
lr_scheduler_args:
  step_size: 30000
  gamma: 0.5
max_batch_frames: 50000
max_batch_size: 2
dataset_size_key: 'lengths'
val_with_vocoder: true
val_check_interval: 2000
num_valid_plots: 10
max_updates: 200000
num_ckpt_keep: 10
permanent_ckpt_start: 120000
permanent_ckpt_interval: 20000


finetune_enabled: false
finetune_ckpt_path: null

finetune_ignored_params:
  - model.fs2.encoder.embed_tokens
  - model.fs2.txt_embed
  - model.fs2.spk_embed
finetune_strict_shapes: true

freezing_enabled: false
frozen_params: []
